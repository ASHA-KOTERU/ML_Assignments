{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asha/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=glob.glob(\"./data/train/*.jpg\")\n",
    "file_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(\"./data/labels.csv\",delimiter=\",\")\n",
    "y_true=y_train['breed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_to_numbers(y_train):\n",
    "    unq=np.unique(y_train)\n",
    "    n=len(unq)\n",
    "    numbers = list(range(0, n))\n",
    "    y_dict=dict(zip(unq,numbers))\n",
    "    y_true=[]\n",
    "    for label in y_train:\n",
    "        n=y_dict[label]\n",
    "        y_true.append(n)\n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=breed_to_numbers(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize_images(image, [224,224])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=tf.one_hot(y_true,120)\n",
    "dataset=tf.data.Dataset.from_tensor_slices((file_names,label))\n",
    "dataset=dataset.map(parse_function)\n",
    "dataset=dataset.batch(batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "x,y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#convolution, relu and max poling for layer 1\n",
    "conv1=tf.layers.conv2d(x,32,3,strides=1,activation=tf.nn.relu)  \n",
    "conv1=tf.layers.max_pooling2d(conv1,2,2,padding='SAME')\n",
    "\n",
    "cov1=tf.layers.batch_normalization(conv1)\n",
    "\n",
    "    \n",
    "#convolution, relu and max poling for layer 2\n",
    "conv2=tf.layers.conv2d(conv1,64,5,strides=1,activation=tf.nn.relu)  \n",
    "conv2=tf.layers.max_pooling2d(conv2,2,2,padding='SAME')\n",
    "conv2=tf.layers.batch_normalization(conv2)\n",
    "\n",
    "\n",
    "conv3=tf.layers.conv2d(conv2,128,5,strides=1,activation=tf.nn.relu)  \n",
    "conv3=tf.layers.max_pooling2d(conv3,2,2,padding='SAME')\n",
    "\n",
    "conv3=tf.layers.batch_normalization(conv3)\n",
    "\n",
    "\n",
    "fc1=tf.contrib.layers.flatten(conv3)\n",
    "#fully connected layer\n",
    "fc1=tf.layers.dense(inputs=fc1, units=2048,activation=tf.nn.relu)\n",
    "fc2=tf.layers.dense(inputs=fc1, units=512,activation=tf.nn.relu)\n",
    "logits=tf.layers.dense(inputs=fc2, units=120)\n",
    "#softmax for probabilities\n",
    "#prob=tf.nn.softmax(logits)\n",
    "    \n",
    "#calculating loss\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "    \n",
    "#calculating accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    }
   ],
   "source": [
    "batches=len(file_names)/batch_size\n",
    "batches=int(batches)\n",
    "epochs=10\n",
    "print batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 running\n",
      "batch 0 loss: 4.7954416 accuracy 0.0\n",
      "batch 10 loss: 4.805768 accuracy 0.0\n",
      "batch 20 loss: 4.787804 accuracy 0.03125\n",
      "batch 30 loss: 4.801465 accuracy 0.0\n",
      "batch 40 loss: 4.80332 accuracy 0.0\n",
      "batch 50 loss: 4.792467 accuracy 0.0\n",
      "batch 60 loss: 4.7799277 accuracy 0.0\n",
      "batch 70 loss: 4.7796984 accuracy 0.0625\n",
      "batch 80 loss: 4.783596 accuracy 0.0\n",
      "batch 90 loss: 4.769043 accuracy 0.03125\n",
      "batch 100 loss: 4.767809 accuracy 0.0\n",
      "batch 110 loss: 4.7925386 accuracy 0.0625\n",
      "batch 120 loss: 4.7974877 accuracy 0.03125\n",
      "batch 130 loss: 4.7799916 accuracy 0.0\n",
      "batch 140 loss: 4.692598 accuracy 0.03125\n",
      "batch 150 loss: 4.798873 accuracy 0.03125\n",
      "batch 160 loss: 4.6637325 accuracy 0.0\n",
      "batch 170 loss: 4.635807 accuracy 0.0625\n",
      "batch 180 loss: 4.770919 accuracy 0.0\n",
      "batch 190 loss: 4.846982 accuracy 0.0\n",
      "batch 200 loss: 4.7438297 accuracy 0.03125\n",
      "batch 210 loss: 4.7422733 accuracy 0.03125\n",
      "batch 220 loss: 4.6512365 accuracy 0.03125\n",
      "batch 230 loss: 4.6019077 accuracy 0.09375\n",
      "batch 240 loss: 4.8059177 accuracy 0.0\n",
      "batch 250 loss: 4.6212106 accuracy 0.03125\n",
      "batch 260 loss: 4.5483246 accuracy 0.0625\n",
      "batch 270 loss: 4.7033253 accuracy 0.03125\n",
      "batch 280 loss: 4.5382204 accuracy 0.03125\n",
      "batch 290 loss: 4.570197 accuracy 0.0\n",
      "batch 300 loss: 4.4775453 accuracy 0.0\n",
      "batch 310 loss: 4.3828416 accuracy 0.0\n",
      "Epoch: 0 ended\n",
      "Epoch: 1 running\n",
      "batch 0 loss: 4.4314184 accuracy 0.03125\n",
      "batch 10 loss: 4.642182 accuracy 0.03125\n",
      "batch 20 loss: 4.448336 accuracy 0.0625\n",
      "batch 30 loss: 4.65683 accuracy 0.03125\n",
      "batch 40 loss: 4.5422573 accuracy 0.0625\n",
      "batch 50 loss: 4.3234844 accuracy 0.03125\n",
      "batch 60 loss: 4.3865914 accuracy 0.0625\n",
      "batch 70 loss: 4.1487484 accuracy 0.09375\n",
      "batch 80 loss: 4.413887 accuracy 0.03125\n",
      "batch 90 loss: 4.4162617 accuracy 0.0\n",
      "batch 100 loss: 4.1370597 accuracy 0.09375\n",
      "batch 110 loss: 4.450223 accuracy 0.0\n",
      "batch 120 loss: 4.1742916 accuracy 0.0625\n",
      "batch 130 loss: 4.257954 accuracy 0.125\n",
      "batch 140 loss: 4.1132994 accuracy 0.15625\n",
      "batch 150 loss: 4.4457455 accuracy 0.03125\n",
      "batch 160 loss: 3.793604 accuracy 0.125\n",
      "batch 170 loss: 3.7574787 accuracy 0.1875\n",
      "batch 180 loss: 4.1825438 accuracy 0.125\n",
      "batch 190 loss: 4.6247025 accuracy 0.03125\n",
      "batch 200 loss: 4.077251 accuracy 0.0625\n",
      "batch 210 loss: 4.2417803 accuracy 0.0625\n",
      "batch 220 loss: 3.966756 accuracy 0.125\n",
      "batch 230 loss: 3.9290159 accuracy 0.0625\n",
      "batch 240 loss: 3.7983549 accuracy 0.28125\n",
      "batch 250 loss: 3.9300447 accuracy 0.1875\n",
      "batch 260 loss: 3.9973564 accuracy 0.09375\n",
      "batch 270 loss: 4.2495747 accuracy 0.0625\n",
      "batch 280 loss: 3.5750005 accuracy 0.15625\n",
      "batch 290 loss: 3.772495 accuracy 0.0625\n",
      "batch 300 loss: 3.6766903 accuracy 0.15625\n",
      "batch 310 loss: 3.506043 accuracy 0.25\n",
      "Epoch: 1 ended\n",
      "Epoch: 2 running\n",
      "batch 0 loss: 3.5405002 accuracy 0.21875\n",
      "batch 10 loss: 3.755305 accuracy 0.125\n",
      "batch 20 loss: 3.4409103 accuracy 0.25\n",
      "batch 30 loss: 3.987976 accuracy 0.09375\n",
      "batch 40 loss: 3.637186 accuracy 0.125\n",
      "batch 50 loss: 3.1342196 accuracy 0.28125\n",
      "batch 60 loss: 3.2228384 accuracy 0.21875\n",
      "batch 70 loss: 3.1868925 accuracy 0.1875\n",
      "batch 80 loss: 3.2865236 accuracy 0.15625\n",
      "batch 90 loss: 3.2293339 accuracy 0.21875\n",
      "batch 100 loss: 3.147317 accuracy 0.375\n",
      "batch 110 loss: 3.5533314 accuracy 0.21875\n",
      "batch 120 loss: 3.2463188 accuracy 0.1875\n",
      "batch 130 loss: 2.9711723 accuracy 0.34375\n",
      "batch 140 loss: 2.860414 accuracy 0.3125\n",
      "batch 150 loss: 3.1333194 accuracy 0.25\n",
      "batch 160 loss: 2.1019273 accuracy 0.46875\n",
      "batch 170 loss: 2.340324 accuracy 0.46875\n",
      "batch 180 loss: 2.7246752 accuracy 0.28125\n",
      "batch 190 loss: 3.4852138 accuracy 0.28125\n",
      "batch 200 loss: 2.3848724 accuracy 0.375\n",
      "batch 210 loss: 2.856361 accuracy 0.25\n",
      "batch 220 loss: 2.118493 accuracy 0.5625\n",
      "batch 230 loss: 2.1715777 accuracy 0.4375\n",
      "batch 240 loss: 2.2736874 accuracy 0.5\n",
      "batch 250 loss: 1.9634134 accuracy 0.5\n",
      "batch 260 loss: 1.8168826 accuracy 0.5625\n",
      "batch 270 loss: 2.5164473 accuracy 0.34375\n",
      "batch 280 loss: 1.2924452 accuracy 0.75\n",
      "batch 290 loss: 1.8590977 accuracy 0.5\n",
      "batch 300 loss: 1.6647954 accuracy 0.5\n",
      "batch 310 loss: 1.8978028 accuracy 0.5\n",
      "Epoch: 2 ended\n",
      "Epoch: 3 running\n",
      "batch 0 loss: 1.2822027 accuracy 0.71875\n",
      "batch 10 loss: 2.0717988 accuracy 0.53125\n",
      "batch 20 loss: 1.8580539 accuracy 0.53125\n",
      "batch 30 loss: 1.5618926 accuracy 0.5625\n",
      "batch 40 loss: 1.5761478 accuracy 0.65625\n",
      "batch 50 loss: 1.322094 accuracy 0.75\n",
      "batch 60 loss: 1.4573991 accuracy 0.6875\n",
      "batch 70 loss: 1.095099 accuracy 0.75\n",
      "batch 80 loss: 1.0872211 accuracy 0.75\n",
      "batch 90 loss: 0.98194224 accuracy 0.75\n",
      "batch 100 loss: 0.90588766 accuracy 0.78125\n",
      "batch 110 loss: 1.8636956 accuracy 0.6875\n",
      "batch 120 loss: 0.87061286 accuracy 0.8125\n",
      "batch 130 loss: 1.0217068 accuracy 0.8125\n",
      "batch 140 loss: 0.86741376 accuracy 0.8125\n",
      "batch 150 loss: 0.93307996 accuracy 0.78125\n",
      "batch 160 loss: 0.48763448 accuracy 0.9375\n",
      "batch 170 loss: 0.89630574 accuracy 0.78125\n",
      "batch 180 loss: 1.0331405 accuracy 0.78125\n",
      "batch 190 loss: 1.1189392 accuracy 0.71875\n",
      "batch 200 loss: 1.0756552 accuracy 0.78125\n",
      "batch 210 loss: 0.51746434 accuracy 0.9375\n",
      "batch 220 loss: 0.5680101 accuracy 0.84375\n",
      "batch 230 loss: 0.5218519 accuracy 0.875\n",
      "batch 240 loss: 0.66014546 accuracy 0.8125\n",
      "batch 250 loss: 0.46715745 accuracy 0.875\n",
      "batch 260 loss: 0.36156 accuracy 0.875\n",
      "batch 270 loss: 1.0133686 accuracy 0.8125\n",
      "batch 280 loss: 0.20505339 accuracy 0.9375\n",
      "batch 290 loss: 0.21533214 accuracy 0.96875\n",
      "batch 300 loss: 0.45658657 accuracy 0.9375\n",
      "batch 310 loss: 0.43573034 accuracy 0.9375\n",
      "Epoch: 3 ended\n",
      "Epoch: 4 running\n",
      "batch 0 loss: 0.41309768 accuracy 0.9375\n",
      "batch 10 loss: 0.54035264 accuracy 0.875\n",
      "batch 20 loss: 0.4095181 accuracy 0.875\n",
      "batch 30 loss: 0.5427333 accuracy 0.875\n",
      "batch 40 loss: 0.2799363 accuracy 0.9375\n",
      "batch 50 loss: 0.32989103 accuracy 0.96875\n",
      "batch 60 loss: 0.85705316 accuracy 0.875\n",
      "batch 70 loss: 0.46075365 accuracy 0.9375\n",
      "batch 80 loss: 0.06683405 accuracy 1.0\n",
      "batch 90 loss: 0.5793784 accuracy 0.8125\n",
      "batch 100 loss: 0.18620645 accuracy 0.96875\n",
      "batch 110 loss: 0.3785976 accuracy 0.84375\n",
      "batch 120 loss: 0.41710573 accuracy 0.875\n",
      "batch 130 loss: 0.26439607 accuracy 0.90625\n",
      "batch 140 loss: 0.18696646 accuracy 0.9375\n",
      "batch 150 loss: 0.27030137 accuracy 0.9375\n",
      "batch 160 loss: 0.4183969 accuracy 0.9375\n",
      "batch 170 loss: 0.4298245 accuracy 0.875\n",
      "batch 180 loss: 0.28639722 accuracy 0.9375\n",
      "batch 190 loss: 0.10806106 accuracy 1.0\n",
      "batch 200 loss: 0.15083557 accuracy 0.96875\n",
      "batch 210 loss: 0.19965732 accuracy 0.96875\n",
      "batch 220 loss: 0.2339364 accuracy 0.90625\n",
      "batch 230 loss: 0.116721824 accuracy 1.0\n",
      "batch 240 loss: 0.09833017 accuracy 0.96875\n",
      "batch 250 loss: 0.25072145 accuracy 0.9375\n",
      "batch 260 loss: 0.4868614 accuracy 0.9375\n",
      "batch 270 loss: 0.17925608 accuracy 0.96875\n",
      "batch 280 loss: 0.11586328 accuracy 0.96875\n",
      "batch 290 loss: 0.06038326 accuracy 0.96875\n",
      "batch 300 loss: 0.09701376 accuracy 0.9375\n",
      "batch 310 loss: 0.12567091 accuracy 0.96875\n",
      "Epoch: 4 ended\n",
      "Epoch: 5 running\n",
      "batch 0 loss: 0.053940102 accuracy 1.0\n",
      "batch 10 loss: 0.2979423 accuracy 0.9375\n",
      "batch 20 loss: 0.1448327 accuracy 1.0\n",
      "batch 30 loss: 0.21089812 accuracy 0.9375\n",
      "batch 40 loss: 0.10768384 accuracy 0.96875\n",
      "batch 50 loss: 0.07668471 accuracy 1.0\n",
      "batch 60 loss: 0.93615973 accuracy 0.875\n",
      "batch 70 loss: 0.16494963 accuracy 0.9375\n",
      "batch 80 loss: 0.07561286 accuracy 1.0\n",
      "batch 90 loss: 0.028742615 accuracy 1.0\n",
      "batch 100 loss: 0.6117906 accuracy 0.875\n",
      "batch 110 loss: 0.13342172 accuracy 0.96875\n",
      "batch 120 loss: 0.106825784 accuracy 0.96875\n",
      "batch 130 loss: 0.023782734 accuracy 1.0\n",
      "batch 140 loss: 0.25977147 accuracy 0.96875\n",
      "batch 150 loss: 0.10767099 accuracy 0.96875\n",
      "batch 160 loss: 0.15956281 accuracy 0.96875\n",
      "batch 170 loss: 0.048842914 accuracy 1.0\n",
      "batch 180 loss: 0.075696245 accuracy 1.0\n",
      "batch 190 loss: 0.082387306 accuracy 1.0\n",
      "batch 200 loss: 0.03149045 accuracy 1.0\n",
      "batch 210 loss: 0.077595845 accuracy 1.0\n",
      "batch 220 loss: 0.03833463 accuracy 1.0\n",
      "batch 230 loss: 0.04437837 accuracy 0.96875\n",
      "batch 240 loss: 0.15797427 accuracy 0.96875\n",
      "batch 250 loss: 0.02130619 accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print \"Epoch:\",epoch ,\"running\"\n",
    "        sess.run(iterator.initializer)\n",
    "        for batch in range(batches):\n",
    "            trainop,loss,acc=sess.run([train_op,loss_op,accuracy])\n",
    "            if batch%10==0:\n",
    "                print \"batch\",batch,\"loss:\",loss,\"accuracy\",acc\n",
    "                 \n",
    "                \n",
    "        print \"Epoch:\",epoch,\"ended\"\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
