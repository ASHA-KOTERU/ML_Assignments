{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [4],\n",
       "       [1],\n",
       "       [9],\n",
       "       [2],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [3],\n",
       "       [5],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [7],\n",
       "       [2],\n",
       "       [8],\n",
       "       [6],\n",
       "       [9],\n",
       "       [4],\n",
       "       [0],\n",
       "       [9],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [2],\n",
       "       [7],\n",
       "       [3],\n",
       "       [8],\n",
       "       [6],\n",
       "       [9],\n",
       "       [0],\n",
       "       [5],\n",
       "       [6],\n",
       "       [0],\n",
       "       [7],\n",
       "       [6],\n",
       "       [1],\n",
       "       [8],\n",
       "       [7],\n",
       "       [9],\n",
       "       [3],\n",
       "       [9],\n",
       "       [8],\n",
       "       [5],\n",
       "       [9],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [7],\n",
       "       [4],\n",
       "       [9],\n",
       "       [8],\n",
       "       [0],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [0],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [7],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [9],\n",
       "       [0],\n",
       "       [2],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [3],\n",
       "       [9],\n",
       "       [0],\n",
       "       [4],\n",
       "       [6],\n",
       "       [7],\n",
       "       [4],\n",
       "       [6],\n",
       "       [8],\n",
       "       [0],\n",
       "       [7],\n",
       "       [8],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [7],\n",
       "       [1],\n",
       "       [7],\n",
       "       [1],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [0],\n",
       "       [2],\n",
       "       [9],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [4],\n",
       "       [9],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [7],\n",
       "       [1],\n",
       "       [8],\n",
       "       [6],\n",
       "       [4],\n",
       "       [1],\n",
       "       [6],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [9],\n",
       "       [1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [8],\n",
       "       [5],\n",
       "       [4],\n",
       "       [7],\n",
       "       [7],\n",
       "       [4],\n",
       "       [2],\n",
       "       [8],\n",
       "       [5],\n",
       "       [8],\n",
       "       [6],\n",
       "       [7],\n",
       "       [3],\n",
       "       [4],\n",
       "       [6],\n",
       "       [1],\n",
       "       [9],\n",
       "       [9],\n",
       "       [6],\n",
       "       [0],\n",
       "       [3],\n",
       "       [7],\n",
       "       [2],\n",
       "       [8],\n",
       "       [2],\n",
       "       [9],\n",
       "       [4],\n",
       "       [4],\n",
       "       [6],\n",
       "       [4],\n",
       "       [9],\n",
       "       [7],\n",
       "       [0],\n",
       "       [9],\n",
       "       [2],\n",
       "       [9],\n",
       "       [5],\n",
       "       [1],\n",
       "       [5],\n",
       "       [9],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [3],\n",
       "       [5],\n",
       "       [9],\n",
       "       [1],\n",
       "       [7],\n",
       "       [6],\n",
       "       [2],\n",
       "       [8],\n",
       "       [2],\n",
       "       [2],\n",
       "       [5],\n",
       "       [0],\n",
       "       [7],\n",
       "       [4],\n",
       "       [9],\n",
       "       [7],\n",
       "       [8],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [8],\n",
       "       [3],\n",
       "       [6],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [7],\n",
       "       [2],\n",
       "       [7],\n",
       "       [3],\n",
       "       [0],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [2],\n",
       "       [6],\n",
       "       [4],\n",
       "       [7],\n",
       "       [1],\n",
       "       [8],\n",
       "       [9],\n",
       "       [9],\n",
       "       [3],\n",
       "       [0],\n",
       "       [7],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [6],\n",
       "       [5],\n",
       "       [8],\n",
       "       [6],\n",
       "       [3],\n",
       "       [7],\n",
       "       [5],\n",
       "       [8],\n",
       "       [0],\n",
       "       [9],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [3],\n",
       "       [6],\n",
       "       [4],\n",
       "       [7],\n",
       "       [5],\n",
       "       [0],\n",
       "       [6],\n",
       "       [2],\n",
       "       [7],\n",
       "       [9],\n",
       "       [8],\n",
       "       [5],\n",
       "       [9],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [4],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [5],\n",
       "       [3],\n",
       "       [9],\n",
       "       [3],\n",
       "       [9],\n",
       "       [0],\n",
       "       [5],\n",
       "       [9],\n",
       "       [6],\n",
       "       [5],\n",
       "       [7],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [4],\n",
       "       [0],\n",
       "       [4],\n",
       "       [8],\n",
       "       [0],\n",
       "       [4],\n",
       "       [3],\n",
       "       [6],\n",
       "       [8],\n",
       "       [7],\n",
       "       [6],\n",
       "       [0],\n",
       "       [9],\n",
       "       [7],\n",
       "       [5],\n",
       "       [7],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [6],\n",
       "       [8],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [5],\n",
       "       [2],\n",
       "       [2],\n",
       "       [9],\n",
       "       [0],\n",
       "       [3],\n",
       "       [9],\n",
       "       [6],\n",
       "       [7],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [3],\n",
       "       [6],\n",
       "       [5],\n",
       "       [8],\n",
       "       [9],\n",
       "       [5],\n",
       "       [4],\n",
       "       [7],\n",
       "       [4],\n",
       "       [2],\n",
       "       [7],\n",
       "       [3],\n",
       "       [4],\n",
       "       [8],\n",
       "       [9],\n",
       "       [1],\n",
       "       [9],\n",
       "       [2],\n",
       "       [8],\n",
       "       [7],\n",
       "       [9],\n",
       "       [1],\n",
       "       [8],\n",
       "       [7],\n",
       "       [4],\n",
       "       [1],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3],\n",
       "       [9],\n",
       "       [4],\n",
       "       [9],\n",
       "       [2],\n",
       "       [1],\n",
       "       [6],\n",
       "       [8],\n",
       "       [4],\n",
       "       [7],\n",
       "       [7],\n",
       "       [4],\n",
       "       [4],\n",
       "       [9],\n",
       "       [2],\n",
       "       [5],\n",
       "       [7],\n",
       "       [2],\n",
       "       [4],\n",
       "       [4],\n",
       "       [2],\n",
       "       [1],\n",
       "       [9],\n",
       "       [7],\n",
       "       [2],\n",
       "       [8],\n",
       "       [7],\n",
       "       [6],\n",
       "       [9],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [8],\n",
       "       [1],\n",
       "       [6],\n",
       "       [5],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [6],\n",
       "       [4],\n",
       "       [5],\n",
       "       [8],\n",
       "       [3],\n",
       "       [1],\n",
       "       [5],\n",
       "       [1],\n",
       "       [9],\n",
       "       [2],\n",
       "       [7],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [8],\n",
       "       [1],\n",
       "       [5],\n",
       "       [8],\n",
       "       [9],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [9],\n",
       "       [9],\n",
       "       [3],\n",
       "       [7],\n",
       "       [0],\n",
       "       [9],\n",
       "       [0],\n",
       "       [6],\n",
       "       [6],\n",
       "       [2],\n",
       "       [3],\n",
       "       [9],\n",
       "       [0],\n",
       "       [7],\n",
       "       [5],\n",
       "       [4],\n",
       "       [8],\n",
       "       [0],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [8],\n",
       "       [7],\n",
       "       [1],\n",
       "       [2],\n",
       "       [6],\n",
       "       [1],\n",
       "       [0],\n",
       "       [3],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [8],\n",
       "       [2],\n",
       "       [0],\n",
       "       [3],\n",
       "       [9],\n",
       "       [4],\n",
       "       [0],\n",
       "       [5],\n",
       "       [0],\n",
       "       [6],\n",
       "       [1],\n",
       "       [7],\n",
       "       [7],\n",
       "       [8],\n",
       "       [1],\n",
       "       [9],\n",
       "       [2],\n",
       "       [0],\n",
       "       [5],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [7],\n",
       "       [3],\n",
       "       [5],\n",
       "       [4],\n",
       "       [9],\n",
       "       [7],\n",
       "       [1],\n",
       "       [8],\n",
       "       [3],\n",
       "       [9],\n",
       "       [6],\n",
       "       [0],\n",
       "       [3],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [6],\n",
       "       [3],\n",
       "       [5],\n",
       "       [7],\n",
       "       [6],\n",
       "       [8],\n",
       "       [3]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv('mnist_train.csv')\n",
    "\n",
    "\n",
    "x=data.drop(data.columns[0], axis=1)\n",
    "y=data[data.columns[0]]\n",
    "X_train = np.array(x.values)\n",
    "Y_train = np.array(y.values)\n",
    "X_train=X_train[:500]\n",
    "Y_train=Y_train[:500]\n",
    "Y_train.reshape(500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j=np.array(X_train[3]).reshape(28,28)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(j,cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W):\n",
    "    s = W * a_slice_prev \n",
    "    Z = np.sum(s)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(x,p):\n",
    "    res=np.pad(x, ((p,p),(p,p)), 'constant', constant_values=0)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution2d(img, f1,p,s):\n",
    "    m, n = f1.shape\n",
    "    a, b = img.shape\n",
    "    r=((a-m+2*p)/s)+1\n",
    "    c=((b-n+2*p)/s)+1\n",
    "    #print \"before padding :\",data.shape\n",
    "    data=zero_pad(img,p)\n",
    "    #print \"after padding :\",data.shape\n",
    "    res=np.zeros(shape=(r,c))\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            x=i+m\n",
    "            y=j+n\n",
    "            a_slice_prev=img[i:x,j:y]\n",
    "            res[i][j]= conv_single_step(a_slice_prev,f1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(z):\n",
    "    y=np.maximum(0,z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_data(X_train,f1,pad,stride):\n",
    "    n=X_train.shape[0]\n",
    "    res=[]\n",
    "    for i in range(n):\n",
    "        j=np.array(X_train[i]).reshape(28,28)\n",
    "        c_j=convolution2d(j,f1,pad,stride)\n",
    "        c_j=np.ravel(c_j)\n",
    "        res.append(c_j)\n",
    "    res=np.array(res)\n",
    "    return res\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exps = np.exp(X - np.max(X))\n",
    "    return exps / np.sum(exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(x,W,b):\n",
    "    res=np.dot(W,x)+b\n",
    "    #res=res/1000\n",
    "    return res\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X_train,Y_train,f1,pad,stride,W,b):\n",
    "    #print \"initial input shape\",X_train.shape\n",
    "    cnvld_x=convolution_data(X_train,f1,pad,stride)\n",
    "    #print \"shape after convolution \",cnvld_x.shape\n",
    "    #print \"convolved_x\",cnvld_x\n",
    "    #print \"convld_x\",np.unique(cnvld_x)\n",
    "    relu_x=ReLu(cnvld_x)\n",
    "    #print \"shape after relu\",relu_x.shape\n",
    "    relu_x=relu_x.T\n",
    "    #print \"shape after relu transpose\",relu_x.shape\n",
    "    #W=np.random.randint(5,size=(10,relu_x.shape[0]))\n",
    "    #b=np.random.randint(1,size=(10,relu_x.shape[1]))\n",
    "    \n",
    "  \n",
    "    #print \"shape of w\",W.shape\n",
    "    #print \"shape of b\",b.shape\n",
    "    output=fc(relu_x,W,b)\n",
    "    #print \"shape of output\", output.shape\n",
    "    prob=softmax(output)\n",
    "    #prob=prob.max(axis=0)\n",
    "    #print \"shape ofy_prob\", prob.shape\n",
    "    loss=calculate_loss(Y_train,prob)\n",
    "    cache=(X_train,cnvld_x,relu_x,output,prob,f1,W,b)\n",
    "    \n",
    "    return cache,loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(y,y_prob):\n",
    "    loss_train=0\n",
    "    y=y.reshape(y.shape[0],1)\n",
    "    y_prob=y_prob.T\n",
    "    m = y.shape[0]\n",
    "    for i in np.arange(m):\n",
    "        loss_train = loss_train+(np.log(y_prob[i,y[i]]))\n",
    "    loss_train = loss_train/m\n",
    "    return -1*loss_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl/da2=da2\n",
    "def der_loss(a2,y):\n",
    "    return np.divide(y,a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#da2/dz2=dz2\n",
    "def der_act2(a2):\n",
    "    return np.multiply(a2,np.subtract(1,a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dz2/da1=da1\n",
    "def der_z2(W2,z2):\n",
    "    return W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivative of relu\n",
    "def der_a1(z1):\n",
    "    return z1*(z1>0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(X,W):\n",
    "    m,n=X.shape\n",
    "    a,b=W.shape\n",
    "    r=m-a+1\n",
    "    c=n-b+1\n",
    "    #res=np.zeros(shape=(a*2,a*2))\n",
    "    res=np.ndarray(shape=(r,c),dtype=type(np.zeros([a,b])))\n",
    "    #res = np.empty(shape=(r,c))\n",
    "    \n",
    "    #print m,n,a,b,r,c\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            e_r=i+a\n",
    "            e_c=j+b\n",
    "            temp=X[i:e_r,j:e_c]\n",
    "            res[i][j]=temp\n",
    "    dw1_temp=np.zeros([3,3])\n",
    "    #print \"res\",res[0]\n",
    "    for i in range(res.shape[1]):\n",
    "        for k in range(res.shape[0]):\n",
    "            dw1_temp=dw1_temp+res[i][k]\n",
    "    \n",
    "    \n",
    "    return dw1_temp\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(cache,y,alpha):\n",
    "    X,z1,a1,z2,a2,W1,W2,b=cache\n",
    "    \n",
    "    \n",
    "    #print \"shape of z1\",z1.shape\n",
    "    \n",
    "    #dl/da2=da2(just the notation)\n",
    "    da2=der_loss(a2,y)\n",
    "    \n",
    "    #da2/dz2=dz2\n",
    "    da2_by_dz2=der_act2(a2)\n",
    "    \n",
    "      \n",
    "    #dl/dw=dw (for updating the weights)\n",
    "    #print \"shape of da2\",da2.shape\n",
    "    #print \"shape of da2_by_dz2\",da2_by_dz2.shape\n",
    "    #print \"shape of a1\", a1.shape\n",
    "    dz2=np.multiply(da2,da2_by_dz2)\n",
    "    dW2=np.dot(dz2,a1.T)/X.shape[0]\n",
    "    #print \"shape of dw2\",dW2.shape\n",
    "    #print \"shape of dz2\",dz2.shape\n",
    "    \n",
    "    #dl/db=db\n",
    "    db=np.sum(da2*da2_by_dz2,axis=1,keepdims=True)/X.shape[0]\n",
    "    \n",
    "    #print \"shape of db\",db.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    #calculating dw1\n",
    "    #dz2/da1=da1\n",
    "    dz2_by_da1=der_z2(W2,z2)\n",
    "    #print \"shape of dz2_by_da1\",dz2_by_da1.shape\n",
    "    #print \"unique values dz2_by_da1\",np.unique(dz2_by_da1)\n",
    "    #print \"unique values of dz2\", np.unique(dz2)\n",
    "\n",
    "    da1_by_dz1=der_a1(z1)\n",
    "    #print \"shape of da1_by_dz1\",da1_by_dz1.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dz1/dw1\n",
    "    dz1_by_dw1=X\n",
    "    #print \"shape of dz1_by_dw1\",dz1_by_dw1.shape\n",
    "    #dl/dw1\n",
    "    #dw1=np.dot(dz2.T,dz2_by_da1)*da1_by_dz1\n",
    "    dw1_temp=np.dot(dz2.T,dz2_by_da1)\n",
    "    #print \"shape of dw1\",dw1.shape\n",
    "    #print \"unique values\",np.unique(dw1)\n",
    "    res_updated_filter=np.zeros([3,3])\n",
    "    for i in range(X.shape[0]):\n",
    "        res_updated_filter=res_updated_filter+func(dw1_temp[i].reshape(26,26),W1)\n",
    "        \n",
    "            \n",
    "    #print \"unique values in res_updated filet\",np.unique(res_updated_filter)\n",
    "    dw1=res_updated_filter\n",
    "   \n",
    "    W1=W1-alpha*dw1\n",
    "    W2=W2=alpha*dW2\n",
    "    b=b-alpha*db\n",
    "    return W1,W2,b\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss [104.96716398]\n",
      "loss [8.52352654]\n",
      "loss [8.52694378]\n",
      "loss [8.52670998]\n",
      "loss [8.52641644]\n",
      "loss [8.52614442]\n",
      "loss [8.5258936]\n",
      "loss [8.52566238]\n",
      "loss [8.52544923]\n",
      "loss [8.52525266]\n",
      "loss [8.52507132]\n",
      "loss [8.52490411]\n",
      "loss [8.52474973]\n",
      "loss [8.52460728]\n",
      "loss [8.52447578]\n",
      "loss [8.52435461]\n",
      "loss [8.52424293]\n",
      "loss [8.52413975]\n",
      "loss [8.52404446]\n",
      "loss [8.52395656]\n"
     ]
    }
   ],
   "source": [
    "W1=np.random.normal(0,.1,(3,3))\n",
    "W2=np.random.normal(0,.1,(10,676))\n",
    "b=np.random.normal(0,.1,(10,X_train.shape[0]))\n",
    "alpha=0.000001\n",
    "loss_function=[]\n",
    "for i in range(20):\n",
    "    cache,loss=forward_prop(X_train,Y_train,W1,0,1,W2,b)\n",
    "    print \"loss\",loss\n",
    "    W1,W2,b=backward_prop(cache,Y_train,alpha)\n",
    "\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_y(X_test,y_test,W1,W2,b):\n",
    "        \n",
    "    cnvld_x=convolution_data(X_train,W1,0,1)\n",
    "   \n",
    "    relu_x=ReLu(cnvld_x)\n",
    "    \n",
    "    relu_x=relu_x.T\n",
    "    \n",
    "    output=fc(relu_x,W2,b)\n",
    "    \n",
    "    prob=softmax(output)\n",
    "    row_index = np.argmax(prob, axis=0)\n",
    "    count=0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if row_index[i]==y_test[i]:\n",
    "            count+=1\n",
    "    acc=float(count)/250\n",
    "            \n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape  (500, 1)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('mnist_test.csv')\n",
    "x=data.drop(data.columns[0], axis=1)\n",
    "y=data[data.columns[0]]\n",
    "X_test = np.array(x.values)\n",
    "Y_test = np.array(y.values)\n",
    "X_test=X_train[:500]\n",
    "Y_test=Y_train[:500]\n",
    "Y_test=Y_test.reshape(500,1)\n",
    "print \"reshape \",Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.192\n"
     ]
    }
   ],
   "source": [
    "acc=pred_y(X_test,Y_test,W1,W2,b)\n",
    "print \"accuracy\",acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
